name: Automation Recon (24/7)

on:
  schedule:
    - cron: '13,33,53 * * * *' 
  workflow_dispatch:

jobs:
  recon-job:
    runs-on: ubuntu-latest
    timeout-minutes: 340
    strategy:
      fail-fast: false
      matrix:
        sniper_id: [1] # Cukup 1 mesin untuk testing
    permissions:
      contents: write
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Cache Seen URLs
        uses: actions/cache@v3
        with:
          path: .seen_urls
          key: seen-urls-cache-${{ github.run_id }}
          restore-keys: |
            seen-urls-cache-

      - name: Set up Go
        uses: actions/setup-go@v4
        with:
          go-version: '>=1.20'

      - name: Install Tools
        run: |
          sudo apt-get update
          # 1. Pasang Google Chrome & Library pendukung
          sudo apt-get install -y google-chrome-stable libnss3 libgbm-dev dnsutils \
            libasound2t64 libatk-bridge2.0-0 libgtk-3-0 libxss1 xvfb libgbm1
          
          # JURUS KUNCI: Symlink agar Katana langsung nemu Chrome sistem
          sudo ln -sf /usr/bin/google-chrome-stable /usr/bin/google-chrome
          
          # 2. Install Tools ProjectDiscovery
          go install -v github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install -v github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
          go install -v github.com/projectdiscovery/katana/cmd/katana@latest
          
          # 3. Install Crawler & Mining Tools
          go install -v github.com/hakluke/hakrawler@latest
          go install -v github.com/tomnomnom/assetfinder@latest
          go install -v github.com/tomnomnom/waybackurls@latest
          go install -v github.com/lc/gau/v2/cmd/gau@latest
          go install -v github.com/tomnomnom/anew@latest
          
          echo "$HOME/go/bin" >> $GITHUB_PATH
          nuclei -ut -silent
          
      - name: Run Predator Recon
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          H1_USERNAME: ${{ secrets.H1_USERNAME }}
          H1_API_KEY: ${{ secrets.H1_API_KEY }}
          TG_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
          TG_CRIT: ${{ secrets.TELEGRAM_CRITICAL_ID }}
          TG_GEN: ${{ secrets.TELEGRAM_GENERAL_ID }}
          TG_DATA: ${{ secrets.TELEGRAM_DATA_ID }}
          KATANA_CHROME_PATH: /usr/bin/google-chrome
        run: |
          # 1. SETUP NOTIF CONFIG
          echo "telegram:" > notify-config.yaml
          echo "  - id: \"p1_p2_alerts\"" >> notify-config.yaml
          echo "    telegram_apikey: \"$TG_TOKEN\"" >> notify-config.yaml
          echo "    telegram_chatid: \"$TG_CRIT\"" >> notify-config.yaml
          echo "    format: \"{{data}}\"" >> notify-config.yaml

          # 2. ANTI-COLLISION DELAY
          SLEEP_TIME=$(( (${{ matrix.sniper_id }} - 1) * 40 ))
          echo "â³ Sniper ${{ matrix.sniper_id }} preparing hyper-speed tools..."
          sleep $SLEEP_TIME

          # --- [MODE TESTING: TARGET KHUSUS VULNWEB] ---
          target_file="targets/test_target.txt"
          program_name="test_target"
          
          echo "ðŸŽ¯ Sniper Special Mission: Engaging $program_name (VULNWEB TEST)"
          mkdir -p "data/$program_name"
          touch .seen_urls

          # STEP 1: DISCOVERY
          subfinder -dL "$target_file" -all -silent -o "data/$program_name/s1.txt" > /dev/null 2>&1 || true
          while read -r domain; do
            echo "$domain" | assetfinder --subs-only >> "data/$program_name/s1.txt" 2>/dev/null || true
          done < "$target_file"
          cat "data/$program_name/s1.txt" | sed 's/*.//g' | tr -d ' ' | sort -u > "data/$program_name/subdomains.txt"

          if [ -s "data/$program_name/subdomains.txt" ]; then
            # STEP 2: HTTPX
            timeout 20m httpx -l "data/$program_name/subdomains.txt" -silent -ip -td -mc 200,301,302,401,403,405 -H "User-Agent: NovaRecon/2026" -o "data/$program_name/active_hosts.txt" > /dev/null 2>&1 || true
            
            if [ -s "data/$program_name/active_hosts.txt" ]; then
                # --- [STEP 3: DEEP SIGHT 3.2 - HYPER SPEED FILTRATION] ---
                echo "[+] Step 3: Mining Endpoints..."
                awk '{print $1}' data/$program_name/active_hosts.txt | sort -u > data/$program_name/active_urls_clean.tmp
                sed 's|http[s]*://||g' data/$program_name/active_urls_clean.tmp | cut -d'/' -f1 | sort -u > data/$program_name/domains_only.txt
                
                touch data/$program_name/urls_wayback.txt data/$program_name/urls_hak.txt data/$program_name/urls_katana.txt
                
                # Mining
                timeout 10m bash -c "cat data/$program_name/domains_only.txt | waybackurls > data/$program_name/urls_wayback.txt" || true
                timeout 10m bash -c "cat data/$program_name/domains_only.txt | gau --subs >> data/$program_name/urls_wayback.txt" || true
                timeout 15m bash -c "cat data/$program_name/active_urls_clean.tmp | hakrawler -subs > data/$program_name/urls_hak.txt" || true
                
                # Katana (Fixed Chrome Path)
                echo "    (Crawling with Katana...)"
                timeout 25m katana -list data/$program_name/active_urls_clean.tmp -system-chrome -headless -no-sandbox -jc -kf all -d 2 -silent -o data/$program_name/urls_katana.txt || true
                
                # GABUNGKAN
                cat data/$program_name/urls_wayback.txt data/$program_name/urls_hak.txt data/$program_name/urls_katana.txt | sort -u > data/$program_name/all_endpoints.txt
                
                # --- SMART FILTER (BUANG SAMPAH) ---
                # Cuma ambil yang berpotensi ada bug (JS, PHP, API, Parameter)
                grep -iE '\.js|\.php|\.aspx|\.jsp|\.json|\/api\/|\?|=' data/$program_name/all_endpoints.txt > data/$program_name/filtered_endpoints.txt || cp data/$program_name/all_endpoints.txt data/$program_name/filtered_endpoints.txt
                
                echo "âœ… Done. Targets filtered from $(wc -l < data/$program_name/all_endpoints.txt) to $(wc -l < data/$program_name/filtered_endpoints.txt)"

                # --- [STEP 4: NUCLEI KILLSHOT] ---
                echo "[+] Phase 1: Deep Scanning Gold (P1-P3)..."
                # Kita tambahkan logika: Jika error 124 (timeout), tetap dianggap sukses (true) agar lanjut ke AI
                timeout 1h nuclei -l "data/$program_name/filtered_endpoints.txt" \
                  -severity critical,high,medium \
                  -et dns,ssl,whois -es info \
                  -rl 100 -c 50 -mhe 100 -no-color \
                  -H "User-Agent: NovaRecon/2026" \
                  -jsonl -o "data/$program_name/nuclei_results.json" || [ $? -eq 124 ] || true

                # STEP 5: TOKEN SCAN
                timeout 15m nuclei -l "data/$program_name/filtered_endpoints.txt" -t http/exposed-tokens/ -rl 150 -no-color -silent -jsonl -o "data/$program_name/token_results.json" || true
                [ -f "data/$program_name/token_results.json" ] && cat "data/$program_name/token_results.json" >> "data/$program_name/nuclei_results.json"

                # STEP 6: AI ANALYSIS
                echo "[+] Step 4: AI Analysis & H1 Drafting..."
                PROGRAM_NAME=$program_name python scripts/validate.py > /dev/null 2>&1 || true

                # STEP 7: NOTIF
                if [ -d "data/$program_name/alerts/high" ]; then
                  for f in data/$program_name/alerts/high/*.md; do
                    [ -e "$f" ] || continue
                    MSG_HIGH=$(cat "$f")
                    curl -s -X POST "https://api.telegram.org/bot$TG_TOKEN/sendMessage" -d "chat_id=$TG_CRIT" -d "text=$MSG_HIGH" > /dev/null 2>&1
                  done
                fi

                zip -qj "${program_name}_FULL_DATA.zip" data/$program_name/*.txt data/$program_name/*.json .seen_urls || true
                curl -s -F chat_id="$TG_DATA" -F document=@"${program_name}_FULL_DATA.zip" -F caption="ðŸ“¦ DATABASE: $program_name" "https://api.telegram.org/bot$TG_TOKEN/sendDocument" > /dev/null 2>&1
            fi
          fi

      - name: Sync Database to Repo
        run: |
          git config --local user.email "bot@sniper-recon.ai"
          git config --local user.name "Recon-Sniper-Bot"
          git add .seen_urls
          git commit -m "database: update seen_urls [skip ci]" || exit 0
          git pull --rebase origin main
          git push
